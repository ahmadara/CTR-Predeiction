{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Necessary Library\n"
      ],
      "metadata": {
        "id": "IcGXwGo4o8gV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w4QFrmePn5uJ",
        "outputId": "cfc4a790-c5b8-400a-ca97-7d4af0aedddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.10\n",
            "  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.10)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.63.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (3.9.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10)\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (24.0)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.16.0)\n",
            "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10)\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (0.37.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10)\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.2)\n",
            "Installing collected packages: tensorboard-plugin-wit, keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "6a324c68cd664be886e9583c7755dc9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepctr[cpu]\n",
            "  Downloading deepctr-0.9.3-py3-none-any.whl (141 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/141.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m133.1/141.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from deepctr[cpu]) (2.31.0)\n",
            "Collecting h5py==3.7.0 (from deepctr[cpu])\n",
            "  Downloading h5py-3.7.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow!=1.7.*,!=1.8.*,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from deepctr[cpu]) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py==3.7.0->deepctr[cpu]) (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.63.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (24.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->deepctr[cpu]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->deepctr[cpu]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->deepctr[cpu]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->deepctr[cpu]) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow!=1.7.*,!=1.8.*,>=1.4.0->deepctr[cpu]) (3.2.2)\n",
            "Installing collected packages: h5py, deepctr\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepctr-0.9.3 h5py-3.7.0\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 99% 1.05G/1.06G [00:09<00:00, 82.6MB/s]\n",
            "100% 1.06G/1.06G [00:09<00:00, 124MB/s] \n",
            "Archive:  /content/amazon-books-reviews.zip\n",
            "  inflating: Books_rating.csv        \n",
            "  inflating: books_data.csv          \n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.10\n",
        "!pip install deepctr[cpu]\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download mohamedbakhet/amazon-books-reviews\n",
        "!unzip /content/amazon-books-reviews.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import log_loss, roc_auc_score , mean_squared_error\n",
        "\n",
        "from itertools import chain\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Dense, Concatenate ,Flatten ,Lambda\n",
        "\n",
        "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr.feature_column import build_input_features, get_linear_logit, DEFAULT_GROUP_NAME, input_from_feature_columns\n",
        "from deepctr.layers.core import PredictionLayer, DNN\n",
        "from deepctr.layers.interaction import FM ,InteractingLayer\n",
        "from deepctr.layers.utils import concat_func, add_func, combined_dnn_input\n",
        "\n",
        "from deepctr.feature_column import build_input_features, get_linear_logit, input_from_feature_columns ,VarLenSparseFeat\n",
        "\n",
        "from deepctr.layers.core import PredictionLayer, DNN ,RegulationModule\n",
        "from deepctr.layers.interaction import CrossNet ,BridgeModule\n",
        "from deepctr.layers.utils import add_func, combined_dnn_input\n"
      ],
      "metadata": {
        "id": "3aIlDcpNpcWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Books_rating.csv\")\n",
        "data=data.dropna()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "nBimWA5fpAcU",
        "outputId": "5907a954-1d50-48c8-b9ae-a1eb071c0282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Id                                              Title  Price  \\\n",
              "10       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
              "11       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
              "12       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
              "13       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
              "14       0595344550                      Whispers of the Wicked Saints  10.95   \n",
              "...             ...                                                ...    ...   \n",
              "2999953  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
              "2999954  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
              "2999955  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
              "2999956  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
              "2999988  0255364520  An End to Welfare Rights: The Rediscovery of I...  18.95   \n",
              "\n",
              "                User_id                              profileName  \\\n",
              "10        AZ0IOBU20TBOP                       Rev. Pamela Tinnin   \n",
              "11       A373VVEU6Z9M0N                     Dr. Terry W. Dorsett   \n",
              "12        AGKGOH65VTRR4          Cynthia L. Lajoy \"Cindy La Joy\"   \n",
              "13        A3OQWLU31BU1Y                            Maxwell Grant   \n",
              "14       A3Q12RK71N74LB                              Book Reader   \n",
              "...                 ...                                      ...   \n",
              "2999953  A1EC8SNPR56CLU                               Denis Dube   \n",
              "2999954  A33VKWCAV9QQKC           Paige E. Steadman \"RuneEnigma\"   \n",
              "2999955  A2PK3NTC9RMEF4                                S. Potter   \n",
              "2999956  A2D0PY6HIGTYIT  Adrian in Phoenix \"No Time for Fantasy\"   \n",
              "2999988  A25JH6CO4DVINS                                 Junglies   \n",
              "\n",
              "        review/helpfulness  review/score  review/time  \\\n",
              "10                    8/10           5.0    991440000   \n",
              "11                     1/1           5.0   1291766400   \n",
              "12                     1/1           5.0   1248307200   \n",
              "13                     1/1           5.0   1222560000   \n",
              "14                    7/11           1.0   1117065600   \n",
              "...                    ...           ...          ...   \n",
              "2999953                0/0           4.0   1285804800   \n",
              "2999954                0/0           5.0   1230249600   \n",
              "2999955                0/0           3.0   1179705600   \n",
              "2999956                5/8           5.0   1111276800   \n",
              "2999988                0/0           4.0   1045526400   \n",
              "\n",
              "                                           review/summary  \\\n",
              "10          Outstanding Resource for Small Church Pastors   \n",
              "11              Small Churches CAN Have Wonderful Worship   \n",
              "12                                  Not Just for Pastors!   \n",
              "13       Small church pastor? This is the book on worship   \n",
              "14                                               not good   \n",
              "...                                                   ...   \n",
              "2999953                         It's the way he writes it   \n",
              "2999954                           Bad Deaths, Great Book!   \n",
              "2999955                                    Still read it.   \n",
              "2999956                        Not another Callahan story   \n",
              "2999988           Heaven helps those who help themselves.   \n",
              "\n",
              "                                               review/text  \n",
              "10       I just finished the book, &quot;Wonderful Wors...  \n",
              "11       Many small churches feel like they can not hav...  \n",
              "12       I just finished reading this amazing book and ...  \n",
              "13       I hadn't been a small church pastor very long ...  \n",
              "14       I bought this book because I read some glowing...  \n",
              "...                                                    ...  \n",
              "2999953  \"Very Bad Death\" is a so so story, but the cha...  \n",
              "2999954  Very Bad Deaths was a very great book! Spider ...  \n",
              "2999955  Anything by Spider Robinson is worth reading. ...  \n",
              "2999956  Great novel! Easy & enjoyable to read straight...  \n",
              "2999988  Another book on welfare reform. Dr. Green invo...  \n",
              "\n",
              "[414518 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cc6d22d-60c4-4870-a1b3-e164fb3570df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Price</th>\n",
              "      <th>User_id</th>\n",
              "      <th>profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0829814000</td>\n",
              "      <td>Wonderful Worship in Smaller Churches</td>\n",
              "      <td>19.40</td>\n",
              "      <td>AZ0IOBU20TBOP</td>\n",
              "      <td>Rev. Pamela Tinnin</td>\n",
              "      <td>8/10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>991440000</td>\n",
              "      <td>Outstanding Resource for Small Church Pastors</td>\n",
              "      <td>I just finished the book, &amp;quot;Wonderful Wors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0829814000</td>\n",
              "      <td>Wonderful Worship in Smaller Churches</td>\n",
              "      <td>19.40</td>\n",
              "      <td>A373VVEU6Z9M0N</td>\n",
              "      <td>Dr. Terry W. Dorsett</td>\n",
              "      <td>1/1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1291766400</td>\n",
              "      <td>Small Churches CAN Have Wonderful Worship</td>\n",
              "      <td>Many small churches feel like they can not hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0829814000</td>\n",
              "      <td>Wonderful Worship in Smaller Churches</td>\n",
              "      <td>19.40</td>\n",
              "      <td>AGKGOH65VTRR4</td>\n",
              "      <td>Cynthia L. Lajoy \"Cindy La Joy\"</td>\n",
              "      <td>1/1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1248307200</td>\n",
              "      <td>Not Just for Pastors!</td>\n",
              "      <td>I just finished reading this amazing book and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0829814000</td>\n",
              "      <td>Wonderful Worship in Smaller Churches</td>\n",
              "      <td>19.40</td>\n",
              "      <td>A3OQWLU31BU1Y</td>\n",
              "      <td>Maxwell Grant</td>\n",
              "      <td>1/1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1222560000</td>\n",
              "      <td>Small church pastor? This is the book on worship</td>\n",
              "      <td>I hadn't been a small church pastor very long ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0595344550</td>\n",
              "      <td>Whispers of the Wicked Saints</td>\n",
              "      <td>10.95</td>\n",
              "      <td>A3Q12RK71N74LB</td>\n",
              "      <td>Book Reader</td>\n",
              "      <td>7/11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1117065600</td>\n",
              "      <td>not good</td>\n",
              "      <td>I bought this book because I read some glowing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999953</th>\n",
              "      <td>0786182431</td>\n",
              "      <td>Very Bad Deaths: Library Edition</td>\n",
              "      <td>90.00</td>\n",
              "      <td>A1EC8SNPR56CLU</td>\n",
              "      <td>Denis Dube</td>\n",
              "      <td>0/0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1285804800</td>\n",
              "      <td>It's the way he writes it</td>\n",
              "      <td>\"Very Bad Death\" is a so so story, but the cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999954</th>\n",
              "      <td>0786182431</td>\n",
              "      <td>Very Bad Deaths: Library Edition</td>\n",
              "      <td>90.00</td>\n",
              "      <td>A33VKWCAV9QQKC</td>\n",
              "      <td>Paige E. Steadman \"RuneEnigma\"</td>\n",
              "      <td>0/0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1230249600</td>\n",
              "      <td>Bad Deaths, Great Book!</td>\n",
              "      <td>Very Bad Deaths was a very great book! Spider ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999955</th>\n",
              "      <td>0786182431</td>\n",
              "      <td>Very Bad Deaths: Library Edition</td>\n",
              "      <td>90.00</td>\n",
              "      <td>A2PK3NTC9RMEF4</td>\n",
              "      <td>S. Potter</td>\n",
              "      <td>0/0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1179705600</td>\n",
              "      <td>Still read it.</td>\n",
              "      <td>Anything by Spider Robinson is worth reading. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999956</th>\n",
              "      <td>0786182431</td>\n",
              "      <td>Very Bad Deaths: Library Edition</td>\n",
              "      <td>90.00</td>\n",
              "      <td>A2D0PY6HIGTYIT</td>\n",
              "      <td>Adrian in Phoenix \"No Time for Fantasy\"</td>\n",
              "      <td>5/8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1111276800</td>\n",
              "      <td>Not another Callahan story</td>\n",
              "      <td>Great novel! Easy &amp; enjoyable to read straight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999988</th>\n",
              "      <td>0255364520</td>\n",
              "      <td>An End to Welfare Rights: The Rediscovery of I...</td>\n",
              "      <td>18.95</td>\n",
              "      <td>A25JH6CO4DVINS</td>\n",
              "      <td>Junglies</td>\n",
              "      <td>0/0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1045526400</td>\n",
              "      <td>Heaven helps those who help themselves.</td>\n",
              "      <td>Another book on welfare reform. Dr. Green invo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>414518 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cc6d22d-60c4-4870-a1b3-e164fb3570df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4cc6d22d-60c4-4870-a1b3-e164fb3570df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4cc6d22d-60c4-4870-a1b3-e164fb3570df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c89ff453-9675-4dd0-bc5d-d210b764f25f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c89ff453-9675-4dd0-bc5d-d210b764f25f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c89ff453-9675-4dd0-bc5d-d210b764f25f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_features = [\"Id\", \"Price\",\n",
        "                    \"User_id\", \"review/helpfulness\", \"review/time\"]\n",
        "target = ['review/score']\n",
        "\n",
        "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feat] = lbe.fit_transform(data[feat])\n",
        "# 2.count #unique features for each sparse field\n",
        "fixlen_feature_columns = [SparseFeat(feat, data[feat].max() + 1, embedding_dim=4)\n",
        "                          for feat in sparse_features]\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# 3.generate input data for model\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=2020)\n",
        "train_model_input = {name: train[name].values for name in feature_names}\n",
        "test_model_input = {name: test[name].values for name in feature_names}\n"
      ],
      "metadata": {
        "id": "5Dp_P3jrqaL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DCN(linear_feature_columns, dnn_feature_columns, cross_num=2, cross_parameterization='vector',\n",
        "        dnn_hidden_units=(256, 128, 64), l2_reg_linear=1e-5, l2_reg_embedding=1e-5,\n",
        "        l2_reg_cross=1e-5, l2_reg_dnn=0, seed=1024, dnn_dropout=0, dnn_use_bn=False,\n",
        "        dnn_activation='relu', task='regression'):\n",
        "\n",
        "    if len(dnn_hidden_units) == 0 and cross_num == 0:\n",
        "        raise ValueError(\"Either hidden_layer or cross layer must > 0\")\n",
        "\n",
        "    features = build_input_features(dnn_feature_columns)\n",
        "    inputs_list = list(features.values())\n",
        "\n",
        "    linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
        "                                    l2_reg=l2_reg_linear)\n",
        "\n",
        "    sparse_embedding_list, dense_value_list = input_from_feature_columns(features, dnn_feature_columns,\n",
        "                                                                         l2_reg_embedding, seed)\n",
        "\n",
        "    dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)\n",
        "\n",
        "    if len(dnn_hidden_units) > 0 and cross_num > 0:  # Deep & Cross\n",
        "        deep_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
        "        cross_out = CrossNet(cross_num, parameterization=cross_parameterization, l2_reg=l2_reg_cross)(dnn_input)\n",
        "        stack_out = Concatenate()([cross_out, deep_out])\n",
        "        final_logit = Dense(1, use_bias=False)(stack_out)\n",
        "    elif len(dnn_hidden_units) > 0:  # Only Deep\n",
        "        deep_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
        "        final_logit = Dense(1, use_bias=False)(deep_out)\n",
        "    elif cross_num > 0:  # Only Cross\n",
        "        cross_out = CrossNet(cross_num, parameterization=cross_parameterization, l2_reg=l2_reg_cross)(dnn_input)\n",
        "        final_logit = Dense(1, use_bias=False)(cross_out)\n",
        "    else:  # Error\n",
        "        raise NotImplementedError\n",
        "\n",
        "    final_logit = add_func([final_logit, linear_logit])\n",
        "    output = PredictionLayer(task)(final_logit)\n",
        "\n",
        "    model = Model(inputs=inputs_list, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "SKLsyTS0qua9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCN(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "\n",
        "history = model.fit(train_model_input, train[target].values,\n",
        "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "print(\"test MSE\", round(mean_squared_error(\n",
        "    test[target].values, pred_ans), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3TgtKWCqyrV",
        "outputId": "b19f76c0-5549-46e0-e8f1-4f4b8f902cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrossNet parameterization: vector\n",
            "Epoch 1/10\n",
            "1037/1037 - 50s - loss: 1.5078 - mse: 1.5055 - val_loss: 1.0387 - val_mse: 1.0330\n",
            "Epoch 2/10\n",
            "1037/1037 - 45s - loss: 0.4441 - mse: 0.4368 - val_loss: 1.0771 - val_mse: 1.0682\n",
            "Epoch 3/10\n",
            "1037/1037 - 54s - loss: 0.2445 - mse: 0.2337 - val_loss: 1.1133 - val_mse: 1.1004\n",
            "Epoch 4/10\n",
            "1037/1037 - 51s - loss: 0.1777 - mse: 0.1640 - val_loss: 1.1006 - val_mse: 1.0858\n",
            "Epoch 5/10\n",
            "1037/1037 - 48s - loss: 0.1342 - mse: 0.1190 - val_loss: 1.1139 - val_mse: 1.0979\n",
            "Epoch 6/10\n",
            "1037/1037 - 45s - loss: 0.1117 - mse: 0.0955 - val_loss: 1.1027 - val_mse: 1.0860\n",
            "Epoch 7/10\n",
            "1037/1037 - 45s - loss: 0.1017 - mse: 0.0849 - val_loss: 1.1180 - val_mse: 1.1007\n",
            "Epoch 8/10\n",
            "1037/1037 - 42s - loss: 0.0926 - mse: 0.0753 - val_loss: 1.1198 - val_mse: 1.1022\n",
            "Epoch 9/10\n",
            "1037/1037 - 55s - loss: 0.0895 - mse: 0.0718 - val_loss: 1.1370 - val_mse: 1.1190\n",
            "Epoch 10/10\n",
            "1037/1037 - 45s - loss: 0.0845 - mse: 0.0667 - val_loss: 1.1653 - val_mse: 1.1474\n",
            "test MSE 1.1333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DIFM(linear_feature_columns, dnn_feature_columns,\n",
        "         att_embedding_size=8, att_head_num=8, att_res=True, dnn_hidden_units=(256, 128, 64),\n",
        "         l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, seed=1024, dnn_dropout=0,\n",
        "         dnn_activation='relu', dnn_use_bn=False, task='regression'):\n",
        "\n",
        "\n",
        "    if not len(dnn_hidden_units) > 0:\n",
        "        raise ValueError(\"dnn_hidden_units is null!\")\n",
        "\n",
        "    features = build_input_features(\n",
        "        linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    sparse_feat_num = len(list(filter(lambda x: isinstance(x, SparseFeat) or isinstance(x, VarLenSparseFeat),\n",
        "                                      dnn_feature_columns)))\n",
        "    inputs_list = list(features.values())\n",
        "\n",
        "    sparse_embedding_list, _ = input_from_feature_columns(features, dnn_feature_columns,\n",
        "                                                          l2_reg_embedding, seed)\n",
        "\n",
        "    if not len(sparse_embedding_list) > 0:\n",
        "        raise ValueError(\"there are no sparse features\")\n",
        "\n",
        "    att_input = concat_func(sparse_embedding_list, axis=1)\n",
        "    att_out = InteractingLayer(att_embedding_size, att_head_num, att_res, scaling=True)(att_input)\n",
        "    att_out = Flatten()(att_out)\n",
        "    m_vec = Dense(sparse_feat_num, use_bias=False)(att_out)\n",
        "\n",
        "    dnn_input = combined_dnn_input(sparse_embedding_list, [])\n",
        "    dnn_output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
        "    m_bit = Dense(sparse_feat_num, use_bias=False)(dnn_output)\n",
        "\n",
        "    input_aware_factor = add_func([m_vec, m_bit])  # the complete input-aware factor m_x\n",
        "\n",
        "    linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
        "                                    l2_reg=l2_reg_linear, sparse_feat_refine_weight=input_aware_factor)\n",
        "\n",
        "    fm_input = concat_func(sparse_embedding_list, axis=1)\n",
        "    refined_fm_input = Lambda(lambda x: x[0] * tf.expand_dims(x[1], axis=-1))(\n",
        "        [fm_input, input_aware_factor])\n",
        "    fm_logit = FM()(refined_fm_input)\n",
        "\n",
        "    final_logit = add_func([linear_logit, fm_logit])\n",
        "\n",
        "    output = PredictionLayer(task)(final_logit)\n",
        "    model = Model(inputs=inputs_list, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "aqtOrtU_txkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DIFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model.compile(\"adam\", \"mse\",\n",
        "              metrics=['accuracy'], )\n",
        "\n",
        "history = model.fit(train_model_input, train[target].values,\n",
        "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "print(\"test MSE\", round(mean_squared_error(\n",
        "    test[target].values, pred_ans), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr5GRifht59I",
        "outputId": "526cd271-aeb2-400d-cf0a-aeef1173e8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1037/1037 - 66s - loss: 2.1720 - accuracy: 0.0609 - val_loss: 1.0939 - val_accuracy: 0.0639\n",
            "Epoch 2/10\n",
            "1037/1037 - 61s - loss: 0.5279 - accuracy: 0.0604 - val_loss: 1.0889 - val_accuracy: 0.0637\n",
            "Epoch 3/10\n",
            "1037/1037 - 76s - loss: 0.2570 - accuracy: 0.0592 - val_loss: 1.0892 - val_accuracy: 0.0638\n",
            "Epoch 4/10\n",
            "1037/1037 - 53s - loss: 0.1641 - accuracy: 0.0608 - val_loss: 1.0904 - val_accuracy: 0.0639\n",
            "Epoch 5/10\n",
            "1037/1037 - 60s - loss: 0.1354 - accuracy: 0.0617 - val_loss: 1.0911 - val_accuracy: 0.0638\n",
            "Epoch 6/10\n",
            "1037/1037 - 60s - loss: 0.1252 - accuracy: 0.0623 - val_loss: 1.1110 - val_accuracy: 0.0639\n",
            "Epoch 7/10\n",
            "1037/1037 - 72s - loss: 0.1171 - accuracy: 0.0628 - val_loss: 1.0889 - val_accuracy: 0.0640\n",
            "Epoch 8/10\n",
            "1037/1037 - 58s - loss: 0.1095 - accuracy: 0.0632 - val_loss: 1.0928 - val_accuracy: 0.0641\n",
            "Epoch 9/10\n",
            "1037/1037 - 53s - loss: 0.1029 - accuracy: 0.0636 - val_loss: 1.0897 - val_accuracy: 0.0639\n",
            "Epoch 10/10\n",
            "1037/1037 - 58s - loss: 0.0996 - accuracy: 0.0638 - val_loss: 1.0934 - val_accuracy: 0.0641\n",
            "test MSE 1.0579\n"
          ]
        }
      ]
    }
  ]
}